{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e3b9a1",
   "metadata": {},
   "source": [
    "## Warmup exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f71b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What the output would be in the case that you apply max pooling with kernel size (i.e., dimension of the filter) \n",
    "equals 3 and stride equals 2? You can either calculate it manually by hand or via Pytorch functions.\n",
    "'''\n",
    "x=torch.tensor([[[[ 2.6987, 82.5899, 76.2929, 26.5976, 13.1088],\n",
    "          [23.0795, 97.8725, 76.6898, 88.7104, 51.1192],\n",
    "          [95.8796, 85.6584, 43.7259,  2.2553, 97.0426],\n",
    "          [99.6418, 38.8225, 80.7951, 33.3520, 83.8901],\n",
    "          [20.7309, 81.9728, 61.7567, 87.1467, 10.1192]]]])\n",
    "\n",
    "##TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72fc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Given a random input as in the example, find the kernel size and the stride in order to have an output of \n",
    "torch.Size([16, 20, 25, 15]). For more details look at the corresponding functions from Pytorch.\"\"\"\n",
    "\n",
    "m = nn.MaxPool2d() ##TODO add the appropriate parameters for the MaxPool2d module\n",
    "input = torch.randn(16, 20, 100, 60)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Given a random input as in the example, find corresponding conv2d parameters to have an ouput \n",
    "of torch.Size([20, 10, 10, 20]). For more details look at the corresponding functions from Pytorch.\"\"\"\n",
    "m = nn.Conv2d() ##TODO add the appropriate parameters for the Conv2d module\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85690049",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ee436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the digits dataset \n",
    "digits = load_digits()\n",
    "x = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = x.shape\n",
    "\n",
    "##TODO reshape your data in such a way that is appropriate as input to the Conv2d module \n",
    "\n",
    "print(\"data shape: \",x.shape)\n",
    "print(\"class shape: \",y.shape)\n",
    "\n",
    "N_train = int(0.8 * x.shape[0])\n",
    "x_train = x[:N_train,:]\n",
    "y_train = y[:N_train]\n",
    "x_test = x[N_train:,:]\n",
    "y_test = y[N_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(x_train, dtype=torch.float)\n",
    "Y_train = torch.tensor(y_train)\n",
    "X_val = torch.tensor(x_test, dtype=torch.float)\n",
    "Y_val = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataset object to support batch training\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features             \n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx], self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        Fill in the Net class in order to build a model that consists of 2 convolutional layers, \n",
    "        one max pooling layer, and three linear layers.\n",
    "        Note that the last linear layer should transform your output to the number of classes. \n",
    "        After each linear layer and each convolutional layer use a relu activate function.\n",
    "        Hint! After the pooling operation you should flatten your data in order to use them as input into the \n",
    "        fully connected layer\n",
    "        \n",
    "        '''\n",
    "        ##TODO fill in your code for the CNN architecture\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model,data):\n",
    "    return model(data).numpy().argmax(axis=1)    \n",
    "def compute_accuracy(predictions,ground_truth):\n",
    "    # Find the prediction (as the classes with highest probabilities)\n",
    "    return (predictions == ground_truth.numpy()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(func,optimizer,learning_rate,num_epochs):\n",
    "    model = func(len(list(set(Y_train.numpy()))))\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer(model.parameters(),lr=learning_rate)\n",
    "    batch_size = 16\n",
    "\n",
    "    # enable batching of training data\n",
    "    train_dataset = Dataset(X_train, Y_train)\n",
    "    dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True)\n",
    "\n",
    "    # keep the accuracy values for each training step\n",
    "    val_accs = np.zeros(num_epochs)\n",
    "\n",
    "    for i_epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i_batch, (X_batch, y_batch) in enumerate(dataloader):\n",
    "            model.zero_grad()  # reset model gradients\n",
    "            output = model(X_batch)  # conduct forward pass  \n",
    "\n",
    "            loss=criterion(output, y_batch) \n",
    "\n",
    "            loss.backward()  # backpropogate loss to calculate gradients\n",
    "            optimizer.step()  # update model weights\n",
    "\n",
    "        with torch.no_grad():  # no need to calculate gradients when assessing accuracy\n",
    "\n",
    "            model.eval()        \n",
    "            pred_train = get_predictions(model,X_train)        \n",
    "            train_acc = compute_accuracy(pred_train, Y_train)\n",
    "            #print(\"Training accuracy: {}\".format(train_acc))       \n",
    "            pred_val = get_predictions(model,X_val)        \n",
    "            val_acc = compute_accuracy(pred_val, Y_val)\n",
    "            val_accs[i_epoch]=val_acc\n",
    "            #print(\"Validation accuracy: {}\".format(val_acc))\n",
    "    \n",
    "    return val_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d47e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam\n",
    "val_acc=run_model(Net,optimizer,learning_rate=0.001,num_epochs=50)\n",
    "plt.plot(val_acc)  \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c438d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "Plot the validation accuracy using different learning rates of [1e-1, 1e-2, 1e-3, 1e-4, 1e-5] by keeping the rest \n",
    "of the hyperparameters fixed. \n",
    "Re-use the code from the previous lab.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "Plot the validation accuracy using different optimizers (Adam, SGD, Adagrad, Adadelta, RMSprop) by keeping the rest\n",
    "of the hyperparameters fixed.\n",
    "Re-use the code from the previous lab.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
